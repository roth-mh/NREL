{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dcaa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5pyd\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf47a0a",
   "metadata": {},
   "source": [
    "### DATA PROCESSING STEPS\n",
    "##### 1. acquiring API KEY\n",
    "##### 2. specifying parameters of interest\n",
    "##### 3. wrangling the api response; reading it as a text and string manipulation to read it into a df\n",
    "##### 4. save pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a54951",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATLONG = \"-87.669888 42.052294\"\n",
    "API_KEY = \"19dv992vs4tNDqBmz2qX5UIWERNrFtyNcHoX6JdH\"\n",
    "\n",
    "base_url = \"https://developer.nrel.gov/api/wind-toolkit/v2/wind/offshore-great-lakes-download.csv?\"\n",
    "params = f\"wkt=POINT({LATLONG})&attributes=wind_speed,wind_direction,pressure,temperature&names=2012&utc=false&leap_day=true&full_name=Mark%20Roth&email=rothmark%40oregonstate.edu&api_key={API_KEY}\"\n",
    "z = requests.get(base_url+params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ee20b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lines = z.text.split(\"\\n\")\n",
    "meta_data = lines[0:2]\n",
    "header_names = lines[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901be73e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = [x.split(\",\") for x in lines[3:]]\n",
    "df = pd.DataFrame(rows)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dbded7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = header_names[0].split(\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42937be3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"~/Desktop/NREL/lakefill_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cac48e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Exploration\n",
    "\n",
    "#### Assumptions:\n",
    "- diurnal means occurring in the daytime (e.g., looking at 6am-6pm of each day) as opposed to daily\n",
    "- I made this assumption because energy consumption varies drastically during the day vs the night\n",
    "- we can change the interpretation of diurnal to mean daily if we switch the \"IS_DAILY\" flag to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b2974b04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as xp\n",
    "import matplotlib\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from statsmodels.tsa.stattools import pacf, acf\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcd722",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Documents/NREL/lakefill_df.csv\")\n",
    "# if not IS_DAILY:\n",
    "#     df = df[df['Hour'] < 18]\n",
    "#     df = df[df['Hour'] > 5]\n",
    "# diurnal_df = df.groupby(['Month', 'Day'], as_index=False).mean()\n",
    "# df_std = df[['Month', 'Day', 'wind speed at 100m (m/s)']].groupby(['Month', 'Day'], as_index=False).agg(np.std)\n",
    "# diurnal_df['wind speed std'] = df_std['wind speed at 100m (m/s)']\n",
    "# diurnal_df = df.groupby(['Month', 'Day'], as_index=False).agg(['mean', np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff388e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# z = df.drop(\"Hour\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ec02a5dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# can be made to take a continuous variable (i.e., number of days to aggregate) \n",
    "# rather than a categorical variable\n",
    "def filter_df_by_time(df, scale, rolling_unit=7, is_daily=True):\n",
    "    \"\"\"\n",
    "    function to filter a dataframe to examine different temporal scales\n",
    "\n",
    "    :param df:      dataframe for filtering; should have the following\n",
    "                    columns: Hour, Day, Month, Year, wind speed at\n",
    "                    100m (m/s)\n",
    "\n",
    "    :param scale:   desired temporal scale for analysis; should be one\n",
    "                    of the following: MONTHLY, HOURLY, DIURNAL\n",
    "\n",
    "    :param rolling_unit:   unit of measurement to calculate rolling avg\n",
    "\n",
    "    :return:        df filtered by the way specified in scale, with the\n",
    "                    addition of (1) the wind speed std calc over the\n",
    "                    same scale and (2) unit rolling average\n",
    "    \"\"\"\n",
    "\n",
    "    if scale == DIURNAL:\n",
    "        if not is_daily:\n",
    "            df = df[df['Hour'] < 19]\n",
    "            df = df[df['Hour'] > 5]\n",
    "        groupby_cols = ['Month', 'Day']\n",
    "        gb_speed = ['Month', 'Day', 'wind speed at 100m (m/s)']\n",
    "    \n",
    "    elif scale == MONTHLY:\n",
    "        groupby_cols = ['Month']\n",
    "        gb_speed = ['Month', 'wind speed at 100m (m/s)']\n",
    "\n",
    "    elif scale == HOURLY:\n",
    "        groupby_cols = ['Month', 'Day', 'Hour']\n",
    "        gb_speed = ['Month', 'Day', 'Hour', 'wind speed at 100m (m/s)']\n",
    "\n",
    "    df_std = df[gb_speed].groupby(groupby_cols, as_index=False).agg(np.std)\n",
    "    df = df.groupby(groupby_cols, as_index=False).mean()\n",
    "    df['wind speed std'] = df_std['wind speed at 100m (m/s)']\n",
    "    df['rolling avg'] = df['wind speed at 100m (m/s)'].rolling(rolling_unit).mean()\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df[['Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "    df['date+hour'] = pd.to_datetime(\n",
    "        df[['Hour', 'Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "\n",
    "    # print(\"filter by time: \" + df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def base_graph(df, scale, highlight_type, var_of_interest=\"wind speed at 100m (m/s)\", thresh=7):\n",
    "    x_axis = 'date'\n",
    "    if scale == HOURLY:\n",
    "        x_axis = 'date+hour'\n",
    "\n",
    "    # TODO: mix btwn hard code and variable var of interest\n",
    "    t0 = go.Bar(\n",
    "        x=df[x_axis],\n",
    "        y=df[var_of_interest],\n",
    "        error_y=dict(\n",
    "                type='data',\n",
    "                array=df[\"wind speed std\"],\n",
    "                visible=True),\n",
    "        name=\"wind speed at 100m (m/s)\"\n",
    "    )\n",
    "    t1 = go.Scatter(x=df[x_axis], y=[df[var_of_interest].mean()]*len(df), name=\"avg wind speed\")\n",
    "    t2 = go.Scatter(x=df[x_axis], y=df[\"rolling avg\"], name=f\"{thresh} unit average: {scale}\")\n",
    "\n",
    "    if highlight_type in [\"top10\", \"above avg\", \"rolling avg\"]:\n",
    "        # this categorical variable could easily be turned into a slider (continuous)\n",
    "        if highlight_type in [\"top10\", \"above avg\"]:\n",
    "            if highlight_type == \"top10\":\n",
    "                q = .9\n",
    "                q_val = df[var_of_interest].quantile(q)\n",
    "                perc = 10\n",
    "            elif highlight_type == \"above avg\":\n",
    "                q_val = df[var_of_interest].mean()\n",
    "                perc = 50\n",
    "\n",
    "            hi_df = df[df[var_of_interest] >= q_val]\n",
    "            reg_df = df[df[var_of_interest] < q_val]\n",
    "            tr_name = f\"TOP {perc}% of wind speeds\"\n",
    "\n",
    "\n",
    "        # find idx with highest 7 day average and work 7 idx back from that\n",
    "        if highlight_type == \"rolling avg\":\n",
    "            idx = df[var_of_interest].idxmax()\n",
    "            hi_df = df.iloc[(idx):(idx+thresh)]\n",
    "            reg_df = df.drop([x for x in range(idx, (idx+thresh))])\n",
    "            tr_name = f\"Greatest 7 Unit Sum of Wind Speed: {scale}\"\n",
    "    \n",
    "        t0 = go.Bar(\n",
    "            x=reg_df[x_axis],\n",
    "            y=reg_df[var_of_interest],\n",
    "            error_y=dict(\n",
    "                    type='data',\n",
    "                    array=reg_df[\"wind speed std\"],\n",
    "                    visible=True),\n",
    "            name=\"wind speed at 100m (m/s)\"\n",
    "        )\n",
    "\n",
    "        t3 = go.Bar(\n",
    "            x=hi_df[x_axis],\n",
    "            y=hi_df[var_of_interest],\n",
    "            error_y=dict(\n",
    "                    type='data',\n",
    "                    array=hi_df[\"wind speed std\"],\n",
    "                    visible=True),\n",
    "            name=tr_name,\n",
    "            marker_color=\"yellow\"\n",
    "        )\n",
    "\n",
    "    traces = [t0, t1]\n",
    "    \n",
    "    if scale in [DIURNAL, HOURLY]:\n",
    "        traces.append(t2)\n",
    "\n",
    "    if highlight_type is not None:\n",
    "        traces.append(t3)\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=f\"{scale} Wind Speed Variability\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Wind Speed at 100m (m/s)\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def agg_by(df, scale=\"Hour\", var_of_interest=\"wind speed at 100m (m/s)\"):\n",
    "    if not IS_DAILY:\n",
    "        df = df[df['Hour'] < 19]\n",
    "        df = df[df['Hour'] > 5]\n",
    "    df = df.groupby([scale], as_index=False).mean()\n",
    "    return df[[scale, var_of_interest]]\n",
    "\n",
    "\n",
    "def heat_map_corr_mat(df, var_of_interest='wind speed at 100m (m/s)'):\n",
    "    EXCLUDE = [\"Hour\", \"Day\", \"date\", \"date+hour\", \"Year\", \"Month\", \"Minute\", \"rolling avg\", \"wind speed std\"]\n",
    "    to_keep = list(set(df.columns) - set(EXCLUDE))\n",
    "    df_corr = df[to_keep]\n",
    "    cors = []\n",
    "    for x in df_corr.columns:\n",
    "        cors.append(str(round(df_corr[var_of_interest].corr(df_corr[x]), 4)))\n",
    "\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "        header=dict(values=['Variable', 'Correlation'],\n",
    "                    line_color='darkslategray',\n",
    "                    fill_color='lightgreen',\n",
    "                    align='center'),\n",
    "        cells=dict(values=[df_corr.columns, # 1st column\n",
    "                           cors], # 2nd column\n",
    "                   line_color='darkslategray',\n",
    "                   fill_color='lightcyan',\n",
    "                   align='center'))\n",
    "    ])\n",
    "    fig.update_layout(title=\"Correlation Table\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_autocorrelation(df, is_partial, var_of_interest=\"wind speed at 100m (m/s)\"):\n",
    "    if is_partial:\n",
    "        df_pacf = pacf(df[var_of_interest])\n",
    "    else:\n",
    "        df_pacf = acf(df[var_of_interest])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x= np.arange(len(df_pacf)),\n",
    "        y= df_pacf,\n",
    "        name= 'PACF',\n",
    "    ))\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(\n",
    "        title=\"Partial Autocorrelation\",\n",
    "        xaxis_title=\"Lag\",\n",
    "        yaxis_title=\"Partial Autocorrelation\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def show_percentile(df, percentiles = None , var_of_interest='wind speed at 100m (m/s)'):\n",
    "    if percentiles is None:\n",
    "\t    percentiles = [.1, .25, .5, .75, .9]\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Percentile', 'Wind Speed (m/s)'],\n",
    "                line_color='darkslategray',\n",
    "                fill_color='lightgreen',\n",
    "                align='center'),\n",
    "    cells=dict(values=[[x*100 for x in percentiles], # 1st column\n",
    "                       [round(df[var_of_interest].quantile(perc), 3) for perc in percentiles]], # 2nd column\n",
    "               line_color='darkslategray',\n",
    "               fill_color='lightcyan',\n",
    "               align='center'))\n",
    "    ])\n",
    "    fig.update_layout(title=\"Percentiles Table\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def calc_most_consec_days(di_df, thresh='mean', var_of_interest='wind speed at 100m (m/s)'):\n",
    "    temp1 = 'Month'\n",
    "    temp2 = 'Day'\n",
    "\n",
    "    di_df['most_consec_days'] = -1\n",
    "    if thresh == 'mean':\n",
    "        avg_val = di_df[var_of_interest].mean()\n",
    "    else:\n",
    "        avg_val = thresh\n",
    "\n",
    "    for m in set(di_df[temp1]):\n",
    "        df_m = di_df[di_df[temp1] == m]\n",
    "        count = 0\n",
    "        max_ct = 0\n",
    "        for d in set(df_m[temp2]):\n",
    "            df_m_d = df_m[df_m[temp2] == d]\n",
    "            # print(df_m_d[var_of_interest].values[0])\n",
    "            if df_m_d[var_of_interest].values[0] >= avg_val:\n",
    "                count += 1\n",
    "                if count > max_ct:\n",
    "                    max_ct = count\n",
    "            else:\n",
    "                count = 0\n",
    "        di_df.most_consec_days[(di_df[temp1] == m)] = max_ct\n",
    "\n",
    "    return di_df[['Year', 'Day', 'Month', 'most_consec_days']].groupby('Month', as_index=False).mean()\n",
    "    # return df[['date', 'Day', 'Month', 'most_consec_days']].groupby('Day', 'Month').mean()\n",
    "\n",
    "def calc_most_consec_hours(df_hours, thresh='mean', var_of_interest='wind speed at 100m (m/s)'):\n",
    "\n",
    "    temp1 = 'Month'\n",
    "    temp2 = 'Day'\n",
    "    temp3 = 'Hour'\n",
    "\n",
    "    if thresh == 'mean':\n",
    "        avg_val = df_hours[var_of_interest].mean()\n",
    "    else:\n",
    "        avg_val = thresh\n",
    "    df_hours['most_consec_hours'] = -1\n",
    "    for m in set(df_hours[temp1]):\n",
    "        df_m = df_hours[df_hours[temp1] == m]\n",
    "        for d in set(df_m[temp2]):\n",
    "            df_m_d = df_m[df_m[temp2] == d]\n",
    "            count = 0\n",
    "            max_ct = 0\n",
    "            for h in set(df_m_d[temp3]):\n",
    "                df_m_d_h = df_m_d[df_m_d[temp3] == h]\n",
    "                # print(df_m_d[var_of_interest].values[0])\n",
    "                if df_m_d_h[var_of_interest].values[0] >= avg_val:\n",
    "                    count += 1\n",
    "                    if count > max_ct:\n",
    "                        max_ct = count\n",
    "                else:\n",
    "                    count = 0\n",
    "            df_hours.most_consec_hours[(df_hours[temp1] == m) & (df_hours[temp2] == d)] = max_ct\n",
    "\n",
    "    return df_hours[['Year', 'Day', 'Month', 'most_consec_hours']].groupby(['Month', 'Day'], as_index=False).mean()\n",
    "\n",
    "\n",
    "def show_consec_graphs(df_to_plot, scale, var_of_interest='wind speed at 100m (m/s)'):\n",
    "    x_axis = 'date'\n",
    "    if scale == DIURNAL:\n",
    "        # df_to_plot = CONSEC_HOURS\n",
    "        var_of_interest = \"most_consec_hours\"\n",
    "        title_name = \"Hours\"\n",
    "    elif scale == MONTHLY:\n",
    "        # df_to_plot = CONSEC_DAYS\n",
    "        var_of_interest = \"most_consec_days\"\n",
    "        title_name = \"Days\"\n",
    "\n",
    "    t0 = go.Bar(\n",
    "        x=df_to_plot[x_axis],\n",
    "        y=df_to_plot[var_of_interest],\n",
    "        name=f\"Consecutive High Wind Speeds {title_name}\",\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[t0])\n",
    "    fig.update_layout(\n",
    "        title=f\"Most Consecutive {title_name} of High Wind Speed Per Time Unit\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=f\"Consecutive {title_name}\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# def show_consec_stats(df, scale, thresh):\n",
    "#     temp1 = 'Month'\n",
    "#     temp2 = 'Day'\n",
    "#     if scale == DIURNAL:\n",
    "#         temp3 = 'Hour'\n",
    "#     # elif scale == MONTHLY:\n",
    "#         # temp1 = 'Day'\n",
    "#\n",
    "#     for m in df[[temp1]]:\n",
    "#         for d in df[[temp2]]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6fdb8a",
   "metadata": {},
   "source": [
    "## DASH components setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0490ffe1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash import Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb82da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to calc consec hours...\n"
     ]
    }
   ],
   "source": [
    "DIURNAL = \"Diurnal\"\n",
    "MONTHLY = \"Monthly\"\n",
    "HOURLY = \"Hourly\"\n",
    "IS_DAILY = True\n",
    "# sacle: replace this w a curl request & data filtering from above\n",
    "df = pd.read_csv(\"~/Documents/NREL/lakefill_df.csv\")\n",
    "df['date'] = pd.to_datetime(\n",
    "    df[['Month', 'Day', 'Year']],\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "df['date+hour'] = pd.to_datetime(\n",
    "    df[['Hour', 'Month', 'Day', 'Year']],\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "print(\"starting to calc consec hours...\")\n",
    "\n",
    "CONSEC_HOURS = calc_most_consec_hours(copy(df))\n",
    "print(\"done precessing hours...\")\n",
    "DI_DF = filter_df_by_time(df, DIURNAL, rolling_unit=7, is_daily=IS_DAILY)\n",
    "print(\"starting to calc consec days...\")\n",
    "CONSEC_DAYS = calc_most_consec_days(copy(DI_DF))\n",
    "print(\"done precessing days...\")\n",
    "MN_DF = filter_df_by_time(df, MONTHLY, rolling_unit=2)\n",
    "\n",
    "CONSEC_DAYS['date'] = pd.to_datetime(\n",
    "        CONSEC_DAYS[['Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    ")\n",
    "\n",
    "CONSEC_HOURS['date'] = pd.to_datetime(\n",
    "    CONSEC_HOURS[['Month', 'Day', 'Year']],\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='base-graph-dropdown',\n",
    "        options=[\n",
    "            {'label': 'Diurnal', 'value': DIURNAL},\n",
    "            {'label': 'Monthly', 'value': MONTHLY},\n",
    "        ],\n",
    "        value=DIURNAL\n",
    "    ),\n",
    "    dcc.Dropdown(id='highlight-graph-dropdown'),\n",
    "    dcc.DatePickerRange(\n",
    "        id='date-range-base',\n",
    "        min_date_allowed=date(2012, 1, 1),\n",
    "        max_date_allowed=date(2012, 12, 31),\n",
    "        initial_visible_month=date(2012, 1, 1),\n",
    "        start_date=date(2012, 1, 1),\n",
    "        end_date=date(2012, 12, 31)\n",
    "    ),\n",
    "    html.Div(id='base-graph-output-container'),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='bar-x-axis',\n",
    "        options=[\n",
    "            {'label': 'Avg Wind by Hour', 'value': 'aWbH'},\n",
    "            {'label': 'Correlation Matrix', 'value': 'CorMat'},\n",
    "            {'label': 'Plot Autocorrelation', 'value': 'ACorr'},\n",
    "            {'label': 'Plot Partial Autocorrelation', 'value': 'PACorr'},\n",
    "            {'label': 'Show Wind Speed Percentiles', 'value': 'percentile'},\n",
    "            # vv todo make this dynamic based on temporal scale to only show one of these vv\n",
    "            {'label': 'Most Number of Consecutive High Wind Hours (DIURNAL)', 'value': 'hi_diurnal'},\n",
    "            {'label': 'Most Number of Consecutive High Wind Days (MONTHLY', 'value': 'hi_monthly'},\n",
    "        ],\n",
    "        value=\"aWbH\"\n",
    "    ),\n",
    "    html.Div(id='bar-output-container')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('highlight-graph-dropdown', 'options'),\n",
    "    Input('base-graph-dropdown', 'value'),\n",
    ")\n",
    "def update_dropdown(temporal_scale):\n",
    "    if temporal_scale in [DIURNAL, HOURLY]:\n",
    "        return [\n",
    "            {'label': 'Top 10%', 'value': 'top10'},\n",
    "            {'label': 'Above Average', 'value': 'above avg'},\n",
    "            {'label': f'Largest 7 {temporal_scale} Period', 'value': 'rolling avg'},\n",
    "        ]\n",
    "    elif temporal_scale == MONTHLY:\n",
    "        return [\n",
    "            {'label': 'Top 10%', 'value': 'top10'},\n",
    "            {'label': 'Above Average', 'value': 'above avg'},\n",
    "        ]\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('base-graph-output-container', 'children'),\n",
    "    Input('base-graph-dropdown', 'value'),\n",
    "    Input('highlight-graph-dropdown', 'value'),\n",
    "    Input('date-range-base', 'start_date'),\n",
    "    Input('date-range-base', 'end_date')\n",
    ")\n",
    "def update_output(temp_scale, highlight_type, start_date, end_date):\n",
    "\n",
    "    if temp_scale == DIURNAL:\n",
    "        df_to_plot = DI_DF\n",
    "    elif temp_scale == MONTHLY:\n",
    "        df_to_plot = MN_DF\n",
    "\n",
    "    # elif temp_scale == HOURLY:\n",
    "    #     df_to_plot = filter_df_by_time(df, HOURLY, rolling_unit=5)\n",
    "    df = df_to_plot[(df_to_plot['date'] >= start_date) & (df_to_plot['date'] <= end_date)]\n",
    "    fig = base_graph(df, temp_scale, highlight_type)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('bar-output-container', 'children'),\n",
    "    Input('bar-x-axis', 'value'),\n",
    "    Input('base-graph-dropdown', 'value'),\n",
    "    Input('date-range-base', 'start_date'),\n",
    "    Input('date-range-base', 'end_date')\n",
    ")\n",
    "# TODO: how to pass objects between functions? does the app have state?\n",
    "def update_secondary(bar_type, temp_input, start_date, end_date, df_base=df):\n",
    "\n",
    "    if bar_type == \"aWbH\":\n",
    "        # it would be nice to have this change based on the\n",
    "        # dynamic x-range that plotly offers\n",
    "        df = df_base[(df_base['date'] >= start_date) & (df_base['date'] <= end_date)]\n",
    "\n",
    "        hist_df = agg_by(df)\n",
    "        t0 = go.Bar(\n",
    "            x=hist_df[\"Hour\"],\n",
    "            y=hist_df[\"wind speed at 100m (m/s)\"],\n",
    "            name=\"wind speed at 100m (m/s)\"\n",
    "        )\n",
    "        traces = [t0]\n",
    "        fig = go.Figure(data=traces)\n",
    "        fig.update_layout(title=f\"Wind Speed Variability X Hour\")\n",
    "\n",
    "    elif bar_type in [\"hi_diurnal\", \"hi_monthly\"]:\n",
    "        if temp_input == DIURNAL:\n",
    "            df_to_plot = CONSEC_HOURS\n",
    "        elif temp_input == MONTHLY:\n",
    "            df_to_plot = CONSEC_DAYS\n",
    "\n",
    "        df_to_plot = df_to_plot[(df_to_plot['date'] >= start_date) & (df_to_plot['date'] <= end_date)]\n",
    "        fig = show_consec_graphs(df_to_plot, temp_input)\n",
    "\n",
    "    else:\n",
    "        if temp_input == DIURNAL:\n",
    "            df_to_plot = DI_DF\n",
    "        elif temp_input == MONTHLY:\n",
    "            df_to_plot = MN_DF\n",
    "        # elif temp_input == HOURLY:\n",
    "        #     df_to_plot = filter_df_by_time(df, HOURLY, rolling_unit=5)\n",
    "        else:\n",
    "            exit(f\"ERROR; bar_type not {DIURNAL} nor {MONTHLY}\")\n",
    "\n",
    "        df_to_plot = df_to_plot[(df_to_plot['date'] >= start_date) & (df_to_plot['date'] <= end_date)]\n",
    "\n",
    "        if bar_type == \"CorMat\":\n",
    "            fig = heat_map_corr_mat(df_to_plot)\n",
    "        elif bar_type == \"PACorr\":\n",
    "            fig = plot_autocorrelation(df_to_plot, is_partial=True)\n",
    "        elif bar_type == \"ACorr\":\n",
    "            fig = plot_autocorrelation(df_to_plot, is_partial=False)\n",
    "        elif bar_type == \"percentile\":\n",
    "            fig = show_percentile(df_to_plot)\n",
    "\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "65a40445",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month  Day  Hour  Minute  wind speed at 100m (m/s)  \\\n",
      "0  2012.0    1.0  1.0   0.0    30.0                     14.86   \n",
      "1  2012.0    1.0  1.0   1.0    30.0                     14.76   \n",
      "2  2012.0    1.0  1.0   2.0    30.0                     15.26   \n",
      "3  2012.0    1.0  1.0   3.0    30.0                     14.56   \n",
      "4  2012.0    1.0  1.0   4.0    30.0                     13.45   \n",
      "\n",
      "   wind direction at 100m (deg)  air pressure at 100m (Pa)  \\\n",
      "0                        179.16                    97110.0   \n",
      "1                        186.39                    96950.0   \n",
      "2                        192.45                    96820.0   \n",
      "3                        203.30                    96680.0   \n",
      "4                        217.14                    96530.0   \n",
      "\n",
      "   air temperature at 100m (C)       date           date+hour  \n",
      "0                         4.57 2012-01-01 2012-01-01 00:00:00  \n",
      "1                         4.94 2012-01-01 2012-01-01 01:00:00  \n",
      "2                         5.11 2012-01-01 2012-01-01 02:00:00  \n",
      "3                         5.27 2012-01-01 2012-01-01 03:00:00  \n",
      "4                         4.94 2012-01-01 2012-01-01 04:00:00  \n"
     ]
    }
   ],
   "source": [
    "def prep_data():\n",
    "    df = pd.read_csv(\"~/Documents/NREL/lakefill_df.csv\")\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df[['Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "    df['date+hour'] = pd.to_datetime(\n",
    "        df[['Hour', 'Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "    print(\"starting to calc consec hours...\")\n",
    "\n",
    "    CONSEC_HOURS = calc_most_consec_hours(copy(df))\n",
    "    print(\"done precessing hours...\")\n",
    "    DI_DF = filter_df_by_time(df, DIURNAL, rolling_unit=7, is_daily=IS_DAILY)\n",
    "    print(\"starting to calc consec days...\")\n",
    "    CONSEC_DAYS = calc_most_consec_days(copy(DI_DF))\n",
    "    print(\"done precessing days...\")\n",
    "    MN_DF = filter_df_by_time(df, MONTHLY, rolling_unit=2)\n",
    "\n",
    "    CONSEC_DAYS['date'] = pd.to_datetime(\n",
    "            CONSEC_DAYS[['Month', 'Day', 'Year']],\n",
    "            infer_datetime_format=True\n",
    "    )\n",
    "\n",
    "    CONSEC_HOURS['date'] = pd.to_datetime(\n",
    "        CONSEC_HOURS[['Month', 'Day', 'Year']],\n",
    "        infer_datetime_format=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NREL",
   "language": "python",
   "name": "nrel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}